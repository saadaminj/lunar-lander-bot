{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0703dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f38877",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,  lr, momentum,_lambda, input_dims, hidden_neurons, output_dims):\n",
    "        # initializing variables for our neural network class using constructor\n",
    "        self.lmbda = _lambda\n",
    "        self.learning_rate = lr\n",
    "        self.momentum = momentum\n",
    "        self.weights = []\n",
    "        self.bias = [1,1]\n",
    "        self.layer_weights = [1] * hidden_neurons\n",
    "        self.delta_weights = []\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        # our activation function\n",
    "        return 1 / (1 + np.exp(-self.lmbda * x))\n",
    "    \n",
    "    def init_weights(self, _layer, _input_dims, _output_dims):\n",
    "        # initializing 3d weights which will carry our weights of each neuron connection in each layer, 1st dimension is layer, second is associated with input layer,\n",
    "        # third is associated with output layer\n",
    "        self.weights.append([])\n",
    "        for i in range(_input_dims+1):  # +1 for bias\n",
    "            self.weights[_layer].append([])\n",
    "            self.weights[_layer][i] = [float(random.uniform(-1,1)) for i in range(_output_dims)]\n",
    "    \n",
    "    def init_delta_weights(self):\n",
    "        # initializing 3d weights which will carry our delta weights (i.e change of weights) of each neuron connection in each layer, 1st dimension is layer, second is associated with input layer,\n",
    "        # third is associated with output layer\n",
    "        for i in range(len(self.weights)):\n",
    "            self.delta_weights.append([])\n",
    "            for j in range(len(self.weights[i])):\n",
    "                self.delta_weights[i].append([])\n",
    "                for k in self.weights[i][j]:\n",
    "                    self.delta_weights[i][j].append(0)\n",
    "    \n",
    "    def performance_measure(self, x, y):\n",
    "        # rmse error function for evaluating the model performance\n",
    "        e = (x - y)**2\n",
    "        e = np.sum(e,axis = 1)/2\n",
    "        print(math.sqrt(np.sum(e,axis = 0)/len(e)),end=' ')\n",
    "        return math.sqrt(np.sum(e,axis = 0)/len(e))\n",
    "    \n",
    "    def forward_pass(self, _inputs):\n",
    "        # forward propagation which multiplies weights and calculate the new layer weights after applying \n",
    "        # the activation function, sigmoid in our case\n",
    "        self.layer_weights = self.sigmoid(np.dot(np.transpose(self.weights[0]), np.hstack((_inputs, [self.bias[0]]))))\n",
    "#         self.layer_weights = self.sigmoid(np.dot(np.transpose(self.weights[0]), _inputs))\n",
    "        # result is the resultant 2 values after our forward pass is completed with the updated weights\n",
    "        _result = self.sigmoid(np.dot(np.transpose(self.weights[1]), np.hstack((self.layer_weights,[self.bias[1]]))))\n",
    "#         _result = self.sigmoid(np.dot(np.transpose(self.weights[1]),self.layer_weights))\n",
    "        self.layer_weights = np.transpose(np.array(self.layer_weights))\n",
    "        return _result\n",
    "    \n",
    "    def backpropagation(self, inputs, outputs, real_outputs):\n",
    "        # backward pass to update the weights using gradient descent algorithm\n",
    "        \n",
    "        # this loop calculates error \n",
    "        error = []\n",
    "        for i in range(0, len(real_outputs)):\n",
    "            error.append(float(real_outputs[i]) - float(outputs[i]))\n",
    "\n",
    "        # this loop calculates gradient value for our 2nd layer\n",
    "        delta_val = []\n",
    "        for i in range(0, len(outputs)):\n",
    "            delta_val.append(self.lmbda * outputs[i] * (1 - outputs[i]) * error[i] )\n",
    "\n",
    "        # this loop calculates gradient value for our 1st layer\n",
    "        delta_val_1 = [] \n",
    "        for i in range(0, len(self.layer_weights)):\n",
    "            result = 0\n",
    "            for j in range(0, len(outputs)):\n",
    "                result = result + ( float(delta_val[j]) * float(self.weights[1][i][j]) ) \n",
    "\n",
    "            delta_val_1.append(self.lmbda * self.layer_weights[i] * (1 - self.layer_weights[i]) * result)\n",
    "        \n",
    "        # this loop calculates delta weights for our 2nd layer using gradient value of 2nd layer calculated before\n",
    "        for i in range(0, len(self.layer_weights)+1):\n",
    "            for j in range(0, len(outputs)):\n",
    "                self.delta_weights[1][i][j] = self.learning_rate * float(delta_val[j]) * float(np.hstack((self.layer_weights,[self.bias[1]]))[i])  + self.momentum * self.delta_weights[1][i][j]\n",
    "#                 self.delta_weights[1][i][j] = self.learning_rate * float(delta_val[j]) * float(self.layer_weights[i])  + self.momentum * self.delta_weights[1][i][j]\n",
    "\n",
    "        # this loop calculates delta weights for our 1st layer using gradient value of 1st layer calculated before\n",
    "        for i in range(0, len(inputs)+1):\n",
    "            for j in range(0, (len(self.layer_weights) - 1)):\n",
    "                self.delta_weights[0][i][j] = self.learning_rate * float(delta_val_1[j]) * float(np.hstack((inputs,[self.bias[0]]))[i])  + self.momentum * self.delta_weights[0][i][j]\n",
    "#                 self.delta_weights[0][i][j] = self.learning_rate * float(delta_val_1[j]) * float(inputs[i])  + self.momentum * self.delta_weights[0][i][j]\n",
    "\n",
    "        # this loop updates weights for our 2nd layer using delta weights of layer 2 calculated before\n",
    "        for i in range(0, len(self.layer_weights)+1):\n",
    "            for j in range(0, len(self.weights[1][i])):\n",
    "                self.weights[1][i][j] = float(self.weights[1][i][j]) + float(self.delta_weights[1][i][j])\n",
    "\n",
    "        # this loop updates weights for our 1st layer using delta weights of layer 1 calculated before\n",
    "        for i in range(0, len(inputs)+1):\n",
    "            for j in range(0, len(self.weights[0][i])):\n",
    "                self.weights[0][i][j] = float(self.weights[0][i][j]) + float(self.delta_weights[0][i][j])\n",
    "    \n",
    "    def training(self, df, y, no_epochs, test_Size, show_graph, stopping_condition):\n",
    "        # this function trains our network\n",
    "        \n",
    "        # intializing variables for storing loss data to calculate graph afterwards\n",
    "        real = []\n",
    "        pred = []\n",
    "        pred_test = []\n",
    "        real_test = []\n",
    "        \n",
    "        epochs = []\n",
    "        rms_train = []\n",
    "        rms_test = []\n",
    "        index = 0\n",
    "        \n",
    "        # iterating over the whole data again and again to train better\n",
    "        for i in range(no_epochs):\n",
    "\n",
    "            print(\"\\nepoch : \"+ str(i),end = \" , error : \")\n",
    "            \n",
    "            #randomizing the training and testing sample before training each epoch\n",
    "            df = df.sample(frac=1).reset_index(drop=True)\n",
    "            \n",
    "            #split the data into training and validation\n",
    "            x_train, x_test, y_train, y_test = train_test_split( df, y, test_size = test_Size, random_state = i)\n",
    "            \n",
    "            # training the model and updating its weights\n",
    "            for x in range(len(x_train)):\n",
    "                _result = self.forward_pass(np.transpose(np.array(x_train.iloc[x])))\n",
    "                real.append(y_train[x])\n",
    "                pred.append(_result)\n",
    "                self.backpropagation(np.array(x_train.iloc[x]),_result, np.array(y_train[x]))\n",
    "            \n",
    "            # evaluating the model performance on validation dataset\n",
    "            for x in range(len(x_test)):\n",
    "                _result = self.forward_pass(np.transpose(np.array(x_test.iloc[x])))\n",
    "                real_test.append(y_test[x])\n",
    "                pred_test.append(_result)\n",
    "\n",
    "            # adding the loss values in the array to plot graph\n",
    "            pm_train = self.performance_measure(pred,np.array(real))\n",
    "            pm_test = self.performance_measure(pred_test,np.array(real_test))\n",
    "            rms_train.append(pm_train)\n",
    "            rms_test.append(pm_test)\n",
    "            epochs.append(index)\n",
    "            index += 1\n",
    "            \n",
    "            # every 10th epoch create a plot for train and validation loss\n",
    "            if(show_graph and i%10 == 0 and i != 0):\n",
    "                \n",
    "                fig, ax = plt.subplots()\n",
    "                fig.set_size_inches(1,1)\n",
    "\n",
    "                ax.plot(epochs, rms_train)\n",
    "                ax.plot(epochs, rms_test)\n",
    "\n",
    "                ax.set(xlabel='epochs', ylabel='loss', title='')\n",
    "            \n",
    "                plt.show()\n",
    "            \n",
    "            # stop the training if 3 digits after decimal are equal that means both training and validation is converging\n",
    "            if(stopping_condition):\n",
    "                if(int(pm_train * 10000) == int(pm_test * 10000)):\n",
    "                    break\n",
    "        \n",
    "        # plot the final graph after all epochs are completed\n",
    "        self.final_plot(epochs, rms_train, rms_test)\n",
    "    \n",
    "    def final_plot(self, epochs, rms_train, rms_test):\n",
    "        # this function plots the final graph for training\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(epochs, rms_train)\n",
    "        ax.plot(epochs, rms_test)\n",
    "\n",
    "        ax.set(xlabel='epochs', ylabel='loss',\n",
    "               title='')\n",
    "        ax.grid()\n",
    "\n",
    "        fig.savefig(\"test.png\")\n",
    "        plt.show()\n",
    "    \n",
    "    def prediction(x):\n",
    "        # this function predicts the x data value\n",
    "        return np.transpose(forward_pass(np.transpose(np.array(x))))\n",
    "    \n",
    "    def write_weights(self):\n",
    "        # this function writes the weights and layer values in the files\n",
    "        np.savetxt('layer_weights2.txt', self.layer_weights)\n",
    "        np.savetxt('weights2.txt', self.weights[0])\n",
    "        np.savetxt('weights_12.txt', self.weights[1])\n",
    "    \n",
    "    def read_weights(self):\n",
    "        # this function read the weights and layer values from the files\n",
    "        self.layer_weights = np.loadtxt('layer_weights2.txt', dtype=float)\n",
    "        self.weights = [[],[]]\n",
    "        self.weights[0] = np.loadtxt('weights2.txt', dtype=float)\n",
    "        self.weights[1] = np.loadtxt('weights_12.txt', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "163080ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.238163</td>\n",
       "      <td>431.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.238163</td>\n",
       "      <td>431.9</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.198163</td>\n",
       "      <td>432.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.198163</td>\n",
       "      <td>432.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43.158163</td>\n",
       "      <td>432.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1    2     3\n",
       "0  43.238163  431.9  0.0  0.00\n",
       "1  43.238163  431.9 -0.1  0.04\n",
       "2  43.198163  432.0 -0.2  0.00\n",
       "3  43.198163  432.2 -0.3  0.04\n",
       "4  43.158163  432.5 -0.4  0.00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data\n",
    "\n",
    "df = pd.read_csv(\"ce889_dataCollection.csv\", header=None)\n",
    "# df = pd.read_csv(\"C:/Users/saada/Desktop/normalized_training.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816c9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative values = 4184\n",
      "positive values = 6524\n",
      "negative values = 6524\n",
      "positive values = 6524\n"
     ]
    }
   ],
   "source": [
    "# get all negative data values and randomize the sample\n",
    "\n",
    "neg_df = df[df[0]<0]\n",
    "neg_df = neg_df.sample(frac=1).reset_index(drop=True)    \n",
    "\n",
    "\n",
    "print('negative values = '+str(len(neg_df)))\n",
    "\n",
    "# get all positive data values and randomize the sample\n",
    "\n",
    "pos_df = df[df[0]>=0]\n",
    "pos_df = pos_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print('positive values = '+str(len(pos_df)))\n",
    "\n",
    "# merge the same number of negative and positive values for stratification and randomize the sample again\n",
    "\n",
    "neg_df = neg_df.iloc[:min(len(pos_df),len(neg_df))]\n",
    "neg_df = [neg_df, neg_df.sample(frac=1).reset_index(drop=True)[0: max(len(pos_df),len(neg_df)) - min(len(pos_df),len(neg_df)) ] ]\n",
    "neg_df = pd.concat(neg_df)\n",
    "\n",
    "print('negative values = '+str(len(neg_df)))\n",
    "\n",
    "pos_df = pos_df.iloc[:min(len(pos_df),len(neg_df))]\n",
    "\n",
    "print('positive values = '+str(len(pos_df)))\n",
    "\n",
    "df = [neg_df, pos_df]\n",
    "df = pd.concat(df)\n",
    "df = df.sample(frac=1).reset_index(drop=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d3db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = (df - df.min()) / (df.max() - df.min())\n",
    "# df.to_csv('normalized_game.csv', sep=',', index= False, header= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df602aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-33.442151</td>\n",
       "      <td>212.530840</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.786623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-480.885996</td>\n",
       "      <td>429.900000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69.507284</td>\n",
       "      <td>247.660946</td>\n",
       "      <td>-0.345235</td>\n",
       "      <td>1.230870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-13.837557</td>\n",
       "      <td>186.973170</td>\n",
       "      <td>0.980721</td>\n",
       "      <td>-0.165896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226.389803</td>\n",
       "      <td>260.126369</td>\n",
       "      <td>0.164640</td>\n",
       "      <td>1.934999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1         2         3\n",
       "0  -33.442151  212.530840 -0.004919 -0.786623\n",
       "1 -480.885996  429.900000  0.700000  0.040000\n",
       "2   69.507284  247.660946 -0.345235  1.230870\n",
       "3  -13.837557  186.973170  0.980721 -0.165896\n",
       "4  226.389803  260.126369  0.164640  1.934999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eac06f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate target and input values and extract min and max values for each column\n",
    "\n",
    "x_target = df[2]\n",
    "y_target = df[3]\n",
    "\n",
    "df = df.drop(2,axis = 1)\n",
    "df = df.drop(3,axis = 1)\n",
    "\n",
    "y = np.transpose([x_target,y_target])\n",
    "\n",
    "ymax_0, ymin_0, ymax_1, ymin_1 = np.transpose(y)[0].max(),np.transpose(y)[0].min(),np.transpose(y)[1].max(),np.transpose(y)[1].min()\n",
    "xmax_0, xmax_1, xmin_0, xmin_1 = df[0].max(),df[1].max(),df[0].min(),df[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78661956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795.2104474142598, 443.3318089433691, -540.428193201501, 65.21097854954758)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xmax_0, xmax_1, xmin_0, xmin_1 # = (806.4610465928558, 632.8696656331233, -725.2383418207205, 65.00338781766072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e38d419f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.999999999999988, -2.742634266708001, 5.01526751404047, -5.603767509880821)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymax_0, ymin_0, ymax_1, ymin_1 # = (7.999999999999988, -4.325720977420088, 6.388370661289141, -7.7609076188105135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c38da102",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_target[np.array(df[0])>=0] = 1\n",
    "x_target[np.array(df[0])<0] = 0\n",
    "y_target[np.array(df[1]>=0 )] = 0.4\n",
    "y = np.transpose([x_target,y_target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ae867cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply min max scaling on data\n",
    "\n",
    "df = (df - df.min()) / (df.max() - df.min())\n",
    "# y = (y - y.min()) / (y.max() - y.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56319389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39285fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init network configs and data\n",
    "\n",
    "_learning_rate = 0.8\n",
    "_momentum = 0.03\n",
    "_lambda = 0.6\n",
    "\n",
    "_input_dims = 2\n",
    "_no_neurons = 4\n",
    "_output_dims = 2\n",
    "\n",
    "network = NeuralNetwork(_learning_rate, _momentum, _lambda, _input_dims, _no_neurons, _output_dims)\n",
    "network.init_weights(0, _input_dims, _no_neurons)\n",
    "network.init_weights(1, _no_neurons, _output_dims)\n",
    "network.init_delta_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf5a541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch : 0 , error : 0.35686290864013537 0.37350522615089693 \n",
      "epoch : 1 , error : 0.3564904297402535 0.36471400679122357 \n",
      "epoch : 2 , error : 0.3562067529370734 0.3626268510049889 \n",
      "epoch : 3 , error : 0.3560855781681377 0.3605647673828256 \n",
      "epoch : 4 , error : 0.35605362842709537 0.358989191462248 \n",
      "epoch : 5 , error : 0.35594694946077593 0.35963798367144795 \n",
      "epoch : 6 , error : 0.3558652493081351 0.3587475212069545 \n",
      "epoch : 7 , error : 0.35586396022188976 0.3580620921942134 \n",
      "epoch : 8 , error : 0.35584981921247144 0.3576367004193754 \n",
      "epoch : 9 , error : 0.35584340428661226 0.357248617210295 \n",
      "epoch : 10 , error : 0.3558169176172241 0.3577561139506901 "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch : 11 , error : 0.35582556412972693 0.35743282770920387 \n",
      "epoch : 12 , error : 0.3558288809730468 0.35714157409455616 \n",
      "epoch : 13 , error : 0.35583376911834286 0.35679208773523374 \n",
      "epoch : 14 , error : 0.3558345098943527 0.3582893285342745 \n",
      "epoch : 15 , error : 0.3558127564982798 0.357791565343781 \n",
      "epoch : 16 , error : 0.35580224395380194 0.35784410418817564 \n",
      "epoch : 17 , error : 0.355814497274057 0.3576748880697358 \n",
      "epoch : 18 , error : 0.3558147943385381 0.3575431984688554 \n",
      "epoch : 19 , error : "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m show_graph \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m stopping_condition \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m network\u001b[39m.\u001b[39;49mtraining(df, y, epochs, test_size, show_graph, stopping_condition)\n",
      "Cell \u001b[1;32mIn[2], line 124\u001b[0m, in \u001b[0;36mNeuralNetwork.training\u001b[1;34m(self, df, y, no_epochs, test_Size, show_graph, stopping_condition)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m# training the model and updating its weights\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x_train)):\n\u001b[1;32m--> 124\u001b[0m     _result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_pass(np\u001b[39m.\u001b[39;49mtranspose(np\u001b[39m.\u001b[39;49marray(x_train\u001b[39m.\u001b[39;49miloc[x])))\n\u001b[0;32m    125\u001b[0m     real\u001b[39m.\u001b[39mappend(y_train[x])\n\u001b[0;32m    126\u001b[0m     pred\u001b[39m.\u001b[39mappend(_result)\n",
      "Cell \u001b[1;32mIn[2], line 45\u001b[0m, in \u001b[0;36mNeuralNetwork.forward_pass\u001b[1;34m(self, _inputs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mforward_pass\u001b[39m(\u001b[39mself\u001b[39m, _inputs):\n\u001b[0;32m     43\u001b[0m         \u001b[39m# forward propagation which multiplies weights and calculate the new layer weights after applying \u001b[39;00m\n\u001b[0;32m     44\u001b[0m         \u001b[39m# the activation function, sigmoid in our case\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_weights \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(np\u001b[39m.\u001b[39;49mdot(np\u001b[39m.\u001b[39;49mtranspose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights[\u001b[39m0\u001b[39;49m]), np\u001b[39m.\u001b[39;49mhstack((_inputs, [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias[\u001b[39m0\u001b[39;49m]]))))\n\u001b[0;32m     46\u001b[0m \u001b[39m#         self.layer_weights = self.sigmoid(np.dot(np.transpose(self.weights[0]), _inputs))\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         \u001b[39m# result is the resultant 2 values after our forward pass is completed with the updated weights\u001b[39;00m\n\u001b[0;32m     48\u001b[0m         _result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid(np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mtranspose(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[\u001b[39m1\u001b[39m]), np\u001b[39m.\u001b[39mhstack((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_weights,[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias[\u001b[39m1\u001b[39m]]))))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# init model configs and train the network\n",
    "\n",
    "epochs = 2000\n",
    "test_size = 0.005\n",
    "show_graph = True\n",
    "stopping_condition = False\n",
    "network.training(df, y, epochs, test_size, show_graph, stopping_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983280cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.write_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322a0c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18080a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f479dd8c04b334504c3400b48a03ddfe7ee10602ff193a5fd21d2755483d242f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
